{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29756587",
   "metadata": {},
   "source": [
    "# Concat_KV with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14842ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1707209249.996837] [s24fvcfastllama-lq2tn:16630:f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import tensorrt as trt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21dbf8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.0a0+6a974be\n",
      "TensorRT version: 8.6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version: \" + torch.__version__)\n",
    "print(\"TensorRT version: \" + trt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5db700",
   "metadata": {},
   "source": [
    "## 0. Generate input and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2575113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "\n",
    "batch_size, seq_len, hidden_size = 4, 45, 4096\n",
    "intermediate_size = 11008\n",
    "num_attention_heads = 32\n",
    "num_key_value_heads = 32\n",
    "max_position_embeddings = 2048\n",
    "rope_theta = 10000.0\n",
    "\n",
    "config[\"hidden_size\"] = hidden_size\n",
    "config[\"num_heads\"] = num_attention_heads\n",
    "config[\"head_dim\"] = config[\"hidden_size\"] // config[\"num_heads\"]\n",
    "config[\"num_key_value_heads\"] = num_key_value_heads\n",
    "config[\"num_key_value_groups\"] = config[\"num_heads\"] // config[\"num_key_value_heads\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c876638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 45, 4096])\n",
      "Input query_states: before reshape torch.Size([4, 45, 4096])\n",
      "tensor([[-0.5055, -0.2720,  0.2262,  ...,  0.6538,  0.3409,  0.1508],\n",
      "        [-0.5055, -0.2720,  0.2262,  ...,  0.6538,  0.3409,  0.1508],\n",
      "        [-0.5055, -0.2720,  0.2262,  ...,  0.6538,  0.3409,  0.1508],\n",
      "        ...,\n",
      "        [-0.5055, -0.2720,  0.2262,  ...,  0.6538,  0.3409,  0.1508],\n",
      "        [-0.5055, -0.2720,  0.2262,  ...,  0.6538,  0.3409,  0.1508],\n",
      "        [-0.5055, -0.2720,  0.2262,  ...,  0.6538,  0.3409,  0.1508]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Input query_states: after reshape torch.Size([4, 32, 45, 128])\n",
      "tensor([[[-5.0549e-01, -2.7203e-01,  2.2621e-01,  ...,  2.0687e-01,\n",
      "           2.7338e-01, -5.8512e-01],\n",
      "         [-5.0549e-01, -2.7203e-01,  2.2621e-01,  ...,  2.0687e-01,\n",
      "           2.7338e-01, -5.8512e-01],\n",
      "         [-5.0549e-01, -2.7203e-01,  2.2621e-01,  ...,  2.0687e-01,\n",
      "           2.7338e-01, -5.8512e-01],\n",
      "         ...,\n",
      "         [-5.0549e-01, -2.7203e-01,  2.2621e-01,  ...,  2.0687e-01,\n",
      "           2.7338e-01, -5.8512e-01],\n",
      "         [-5.0549e-01, -2.7203e-01,  2.2621e-01,  ...,  2.0687e-01,\n",
      "           2.7338e-01, -5.8512e-01],\n",
      "         [-5.0549e-01, -2.7203e-01,  2.2621e-01,  ...,  2.0687e-01,\n",
      "           2.7338e-01, -5.8512e-01]],\n",
      "\n",
      "        [[-1.9367e-01,  3.0119e-01,  1.6036e-01,  ...,  8.5629e-02,\n",
      "           4.5609e-01, -5.5028e-01],\n",
      "         [-1.9367e-01,  3.0119e-01,  1.6036e-01,  ...,  8.5629e-02,\n",
      "           4.5609e-01, -5.5028e-01],\n",
      "         [-1.9367e-01,  3.0119e-01,  1.6036e-01,  ...,  8.5629e-02,\n",
      "           4.5609e-01, -5.5028e-01],\n",
      "         ...,\n",
      "         [-1.9367e-01,  3.0119e-01,  1.6036e-01,  ...,  8.5629e-02,\n",
      "           4.5609e-01, -5.5028e-01],\n",
      "         [-1.9367e-01,  3.0119e-01,  1.6036e-01,  ...,  8.5629e-02,\n",
      "           4.5609e-01, -5.5028e-01],\n",
      "         [-1.9367e-01,  3.0119e-01,  1.6036e-01,  ...,  8.5629e-02,\n",
      "           4.5609e-01, -5.5028e-01]],\n",
      "\n",
      "        [[-7.8739e-01, -6.5524e-02,  1.7219e-01,  ..., -8.5610e-01,\n",
      "           3.5772e-01, -5.6617e-01],\n",
      "         [-7.8739e-01, -6.5524e-02,  1.7219e-01,  ..., -8.5610e-01,\n",
      "           3.5772e-01, -5.6617e-01],\n",
      "         [-7.8739e-01, -6.5524e-02,  1.7219e-01,  ..., -8.5610e-01,\n",
      "           3.5772e-01, -5.6617e-01],\n",
      "         ...,\n",
      "         [-7.8739e-01, -6.5524e-02,  1.7219e-01,  ..., -8.5610e-01,\n",
      "           3.5772e-01, -5.6617e-01],\n",
      "         [-7.8739e-01, -6.5524e-02,  1.7219e-01,  ..., -8.5610e-01,\n",
      "           3.5772e-01, -5.6617e-01],\n",
      "         [-7.8739e-01, -6.5524e-02,  1.7219e-01,  ..., -8.5610e-01,\n",
      "           3.5772e-01, -5.6617e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4300e+00,  8.9435e-02, -3.7561e-01,  ...,  6.7157e-01,\n",
      "          -2.5438e-01,  7.7339e-01],\n",
      "         [ 1.4300e+00,  8.9435e-02, -3.7561e-01,  ...,  6.7157e-01,\n",
      "          -2.5438e-01,  7.7339e-01],\n",
      "         [ 1.4300e+00,  8.9435e-02, -3.7561e-01,  ...,  6.7157e-01,\n",
      "          -2.5438e-01,  7.7339e-01],\n",
      "         ...,\n",
      "         [ 1.4300e+00,  8.9435e-02, -3.7561e-01,  ...,  6.7157e-01,\n",
      "          -2.5438e-01,  7.7339e-01],\n",
      "         [ 1.4300e+00,  8.9435e-02, -3.7561e-01,  ...,  6.7157e-01,\n",
      "          -2.5438e-01,  7.7339e-01],\n",
      "         [ 1.4300e+00,  8.9435e-02, -3.7561e-01,  ...,  6.7157e-01,\n",
      "          -2.5438e-01,  7.7339e-01]],\n",
      "\n",
      "        [[-4.2052e-01,  6.9354e-04,  2.7123e-01,  ...,  5.7163e-01,\n",
      "          -3.3913e-01, -4.4766e-02],\n",
      "         [-4.2052e-01,  6.9354e-04,  2.7123e-01,  ...,  5.7163e-01,\n",
      "          -3.3913e-01, -4.4766e-02],\n",
      "         [-4.2052e-01,  6.9354e-04,  2.7123e-01,  ...,  5.7163e-01,\n",
      "          -3.3913e-01, -4.4766e-02],\n",
      "         ...,\n",
      "         [-4.2052e-01,  6.9354e-04,  2.7123e-01,  ...,  5.7163e-01,\n",
      "          -3.3913e-01, -4.4766e-02],\n",
      "         [-4.2052e-01,  6.9354e-04,  2.7123e-01,  ...,  5.7163e-01,\n",
      "          -3.3913e-01, -4.4766e-02],\n",
      "         [-4.2052e-01,  6.9354e-04,  2.7123e-01,  ...,  5.7163e-01,\n",
      "          -3.3913e-01, -4.4766e-02]],\n",
      "\n",
      "        [[ 8.7608e-02,  2.2924e-01, -1.1868e-01,  ...,  6.5385e-01,\n",
      "           3.4086e-01,  1.5077e-01],\n",
      "         [ 8.7608e-02,  2.2924e-01, -1.1868e-01,  ...,  6.5385e-01,\n",
      "           3.4086e-01,  1.5077e-01],\n",
      "         [ 8.7608e-02,  2.2924e-01, -1.1868e-01,  ...,  6.5385e-01,\n",
      "           3.4086e-01,  1.5077e-01],\n",
      "         ...,\n",
      "         [ 8.7608e-02,  2.2924e-01, -1.1868e-01,  ...,  6.5385e-01,\n",
      "           3.4086e-01,  1.5077e-01],\n",
      "         [ 8.7608e-02,  2.2924e-01, -1.1868e-01,  ...,  6.5385e-01,\n",
      "           3.4086e-01,  1.5077e-01],\n",
      "         [ 8.7608e-02,  2.2924e-01, -1.1868e-01,  ...,  6.5385e-01,\n",
      "           3.4086e-01,  1.5077e-01]]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = torch.ones(batch_size, seq_len, hidden_size)\n",
    "print(data.shape)\n",
    "\n",
    "## Prepare Pytorch Testing Parameter\n",
    "q_proj = nn.Linear(config[\"hidden_size\"], config[\"num_heads\"] * config[\"hidden_size\"] // config[\"num_heads\"], bias=False)\n",
    "k_proj = nn.Linear(config[\"hidden_size\"], config[\"num_key_value_heads\"] * config[\"head_dim\"], bias=False)\n",
    "v_proj = nn.Linear(config[\"hidden_size\"], config[\"num_key_value_heads\"] * config[\"head_dim\"], bias=False)\n",
    "\n",
    "query_states = q_proj(data)\n",
    "key_states = k_proj(data)\n",
    "value_states = v_proj(data)\n",
    "print(\"Input query_states: before reshape \" +str(query_states.shape))\n",
    "print(query_states[0])\n",
    "bsz, q_len, _ = data.size()\n",
    "\n",
    "# reshape\n",
    "query_states = query_states.view(bsz, q_len, config[\"num_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "key_states = key_states.view(bsz, q_len, config[\"num_key_value_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "value_states = value_states.view(bsz, q_len, config[\"num_key_value_heads\"], config[\"head_dim\"]).transpose(1, 2)\n",
    "print(\"Input query_states: after reshape \" + str(query_states.shape))\n",
    "print(query_states[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d39d6",
   "metadata": {},
   "source": [
    "## 1. Concat_kv with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f746cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####################################################\n",
    "# # in hugging face, they do have kv cache, however, they don't have other attention optimization\n",
    "# # this could be done directly in tensorRT by using dynamic shape\n",
    "# kv_seq_len = key_states.shape[-2]\n",
    "# if past_key_value is not None:\n",
    "#     kv_seq_len += past_key_value[0].shape[-2]\n",
    "\n",
    "# query_states, key_states = self.rotary_emb(query_states, key_states, value_states, position_ids, seq_len=q_len)\n",
    "\n",
    "# if past_key_value is not None:\n",
    "#     # reuse k, v, self_attention\n",
    "#     key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
    "#     value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
    "\n",
    "# past_key_value = (key_states, value_states) if use_cache else None\n",
    "\n",
    "# print(self.num_key_value_groups)\n",
    "# # repeat k/v heads if n_kv_heads < n_heads\n",
    "# key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "# value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "# #####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46b8be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_kv(hidden_states: torch.Tensor, hidden_states_2: torch.Tensor,) -> torch.Tensor:\n",
    "    print(\"Input shape : \")\n",
    "    print(hidden_states.shape)\n",
    "    new_states = torch.cat([hidden_states, hidden_states_2], dim=2)\n",
    "    print(\"Output shape : \")\n",
    "    print(new_states.shape)\n",
    "    return new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0e0afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : \n",
      "torch.Size([4, 32, 45, 128])\n",
      "Output shape : \n",
      "torch.Size([4, 32, 90, 128])\n"
     ]
    }
   ],
   "source": [
    "concat_key_states = concat_kv(key_states, key_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b313d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 90, 128])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_key_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b4204",
   "metadata": {},
   "source": [
    "## 2. Concat_kv with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f83176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_create(batch_size, num_attention_heads, dim):\n",
    "    # Config TensorRT Logger, Builder, Network\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # inputs: hidden_state, n_rep with dynamic shape\n",
    "    hidden_states = network.add_input('hidden_states', trt.DataType.FLOAT, (batch_size, num_attention_heads, -1, dim))\n",
    "    hidden_states_2 = network.add_input('hidden_states_2', trt.DataType.FLOAT, (batch_size, num_attention_heads, -1, dim))\n",
    "    \n",
    "    # dynamic shape optimization\n",
    "    profile = builder.create_optimization_profile();\n",
    "    profile.set_shape(\"hidden_states\", \n",
    "                      (batch_size, num_attention_heads, 1, dim), \n",
    "                      (batch_size, num_attention_heads, 45, dim), \n",
    "                      (batch_size, num_attention_heads, 1024, dim))\n",
    "    profile.set_shape(\"hidden_states_2\", \n",
    "                      (batch_size, num_attention_heads, 1, dim), \n",
    "                      (batch_size, num_attention_heads, 45, dim), \n",
    "                      (batch_size, num_attention_heads, 1024, dim)) \n",
    "    \n",
    "    config.add_optimization_profile(profile)\n",
    "    \n",
    "    print(\"- 0) input: hidden_states, repeat_states shape :\")\n",
    "    print(hidden_states.shape, hidden_states_2.shape)\n",
    "\n",
    "    print(\"- 1) Get concat_states shape:\")\n",
    "    concat_states = network.add_concatenation([hidden_states, hidden_states_2])\n",
    "    concat_states.axis = 2\n",
    "    \n",
    "    print(concat_states.get_output(0).shape)\n",
    "  \n",
    "    network.mark_output(concat_states.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e92b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0) input: hidden_states, repeat_states shape :\n",
      "(4, 32, -1, 128) (4, 32, -1, 128)\n",
      "- 1) Get concat_states shape:\n",
      "(4, 32, -1, 128)\n"
     ]
    }
   ],
   "source": [
    "trt_engineStr = trt_create(batch_size = batch_size, \n",
    "                           num_attention_heads = config[\"num_heads\"],\n",
    "                           dim = config[\"head_dim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79311749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(batch_size, num_attention_heads, dim, engineString, h_state, h_state_2): \n",
    "\n",
    "    print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "    print(\"Set input shape: hidden_states\")\n",
    "    #context.active_optimization_profile = 0\n",
    "    \n",
    "    h_shape = context.get_binding_shape(0)\n",
    "    print(h_shape)\n",
    "    context.set_input_shape(\"hidden_states\", (batch_size, num_attention_heads, seq_len, dim))\n",
    "    context.set_binding_shape(0, (batch_size, num_attention_heads, seq_len, dim))\n",
    "\n",
    "    print(\"Set input shape: repeat_states\")\n",
    "    h_shape_2 = context.get_binding_shape(1)\n",
    "    print(h_shape_2)\n",
    "    context.set_input_shape(\"hidden_states_2\", (batch_size, num_attention_heads, seq_len, dim))\n",
    "    context.set_binding_shape(1, (batch_size, num_attention_heads, seq_len, dim))\n",
    " \n",
    "    print(\"Set input shape completed\")\n",
    "\n",
    "    h_state_data = np.array(h_state)\n",
    "    h_state_2_data = np.array(h_state_2)\n",
    "    \n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(h_state_data.reshape(-1))\n",
    "    inputH1 = np.ascontiguousarray(h_state_2_data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, inputD1 = cudart.cudaMallocAsync(inputH1.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "   \n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    cudart.cudaMemcpyAsync(inputD1, inputH1.ctypes.data, inputH1.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    \n",
    "    # execute\n",
    "#     print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(inputD1), int(outputD0)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "    \n",
    "    # wait for everythidden_sizeg\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(inputD1)\n",
    "    cudart.cudaFree(outputD0)\n",
    "\n",
    "    return outputH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56422461",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_state = key_states.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d45246c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime\n",
      "Set input shape: hidden_states\n",
      "(4, 32, -1, 128)\n",
      "Set input shape: repeat_states\n",
      "(4, 32, -1, 128)\n",
      "Set input shape completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16630/635602852.py:12: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  h_shape = context.get_binding_shape(0)\n",
      "/tmp/ipykernel_16630/635602852.py:15: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, (batch_size, num_attention_heads, seq_len, dim))\n",
      "/tmp/ipykernel_16630/635602852.py:18: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  h_shape_2 = context.get_binding_shape(1)\n",
      "/tmp/ipykernel_16630/635602852.py:21: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(1, (batch_size, num_attention_heads, seq_len, dim))\n",
      "/tmp/ipykernel_16630/635602852.py:32: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
      "/tmp/ipykernel_16630/635602852.py:32: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n"
     ]
    }
   ],
   "source": [
    "trt_output = trt_inference(batch_size, config[\"num_heads\"], config[\"head_dim\"],\n",
    "                           trt_engineStr, \n",
    "                           h_state, h_state)\n",
    "\n",
    "trt_concat_states = trt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ff765d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 32, 90, 128]), (4, 32, 90, 128))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_key_states.shape, trt_concat_states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d799224",
   "metadata": {},
   "source": [
    "## Is the result valid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ec18dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(concat_key_states.clone().detach().cpu().numpy(), trt_concat_states, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "385778f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1583,  0.9145,  0.6136,  ...,  0.3857, -0.1275,  1.2276],\n",
       "         [-0.1583,  0.9145,  0.6136,  ...,  0.3857, -0.1275,  1.2276],\n",
       "         [-0.1583,  0.9145,  0.6136,  ...,  0.3857, -0.1275,  1.2276],\n",
       "         ...,\n",
       "         [-0.1583,  0.9145,  0.6136,  ...,  0.3857, -0.1275,  1.2276],\n",
       "         [-0.1583,  0.9145,  0.6136,  ...,  0.3857, -0.1275,  1.2276],\n",
       "         [-0.1583,  0.9145,  0.6136,  ...,  0.3857, -0.1275,  1.2276]],\n",
       "\n",
       "        [[-0.8143,  0.3838,  0.8605,  ...,  0.1744,  0.0748,  0.2109],\n",
       "         [-0.8143,  0.3838,  0.8605,  ...,  0.1744,  0.0748,  0.2109],\n",
       "         [-0.8143,  0.3838,  0.8605,  ...,  0.1744,  0.0748,  0.2109],\n",
       "         ...,\n",
       "         [-0.8143,  0.3838,  0.8605,  ...,  0.1744,  0.0748,  0.2109],\n",
       "         [-0.8143,  0.3838,  0.8605,  ...,  0.1744,  0.0748,  0.2109],\n",
       "         [-0.8143,  0.3838,  0.8605,  ...,  0.1744,  0.0748,  0.2109]],\n",
       "\n",
       "        [[-0.1133,  0.7169,  0.5253,  ...,  0.3483,  0.0329,  0.0952],\n",
       "         [-0.1133,  0.7169,  0.5253,  ...,  0.3483,  0.0329,  0.0952],\n",
       "         [-0.1133,  0.7169,  0.5253,  ...,  0.3483,  0.0329,  0.0952],\n",
       "         ...,\n",
       "         [-0.1133,  0.7169,  0.5253,  ...,  0.3483,  0.0329,  0.0952],\n",
       "         [-0.1133,  0.7169,  0.5253,  ...,  0.3483,  0.0329,  0.0952],\n",
       "         [-0.1133,  0.7169,  0.5253,  ...,  0.3483,  0.0329,  0.0952]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.7157, -0.3532,  0.3676,  ...,  0.0066, -0.8199, -0.9024],\n",
       "         [-0.7157, -0.3532,  0.3676,  ...,  0.0066, -0.8199, -0.9024],\n",
       "         [-0.7157, -0.3532,  0.3676,  ...,  0.0066, -0.8199, -0.9024],\n",
       "         ...,\n",
       "         [-0.7157, -0.3532,  0.3676,  ...,  0.0066, -0.8199, -0.9024],\n",
       "         [-0.7157, -0.3532,  0.3676,  ...,  0.0066, -0.8199, -0.9024],\n",
       "         [-0.7157, -0.3532,  0.3676,  ...,  0.0066, -0.8199, -0.9024]],\n",
       "\n",
       "        [[-0.4999, -1.3084, -0.4911,  ...,  0.1012,  0.1457, -0.8852],\n",
       "         [-0.4999, -1.3084, -0.4911,  ...,  0.1012,  0.1457, -0.8852],\n",
       "         [-0.4999, -1.3084, -0.4911,  ...,  0.1012,  0.1457, -0.8852],\n",
       "         ...,\n",
       "         [-0.4999, -1.3084, -0.4911,  ...,  0.1012,  0.1457, -0.8852],\n",
       "         [-0.4999, -1.3084, -0.4911,  ...,  0.1012,  0.1457, -0.8852],\n",
       "         [-0.4999, -1.3084, -0.4911,  ...,  0.1012,  0.1457, -0.8852]],\n",
       "\n",
       "        [[ 0.7451,  0.7043, -0.2324,  ...,  0.1579,  0.2597,  0.2180],\n",
       "         [ 0.7451,  0.7043, -0.2324,  ...,  0.1579,  0.2597,  0.2180],\n",
       "         [ 0.7451,  0.7043, -0.2324,  ...,  0.1579,  0.2597,  0.2180],\n",
       "         ...,\n",
       "         [ 0.7451,  0.7043, -0.2324,  ...,  0.1579,  0.2597,  0.2180],\n",
       "         [ 0.7451,  0.7043, -0.2324,  ...,  0.1579,  0.2597,  0.2180],\n",
       "         [ 0.7451,  0.7043, -0.2324,  ...,  0.1579,  0.2597,  0.2180]]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_key_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67ab6939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.15834486,  0.91452134,  0.6135675 , ...,  0.38571906,\n",
       "         -0.12748194,  1.227637  ],\n",
       "        [-0.15834486,  0.91452134,  0.6135675 , ...,  0.38571906,\n",
       "         -0.12748194,  1.227637  ],\n",
       "        [-0.15834486,  0.91452134,  0.6135675 , ...,  0.38571906,\n",
       "         -0.12748194,  1.227637  ],\n",
       "        ...,\n",
       "        [-0.15834486,  0.91452134,  0.6135675 , ...,  0.38571906,\n",
       "         -0.12748194,  1.227637  ],\n",
       "        [-0.15834486,  0.91452134,  0.6135675 , ...,  0.38571906,\n",
       "         -0.12748194,  1.227637  ],\n",
       "        [-0.15834486,  0.91452134,  0.6135675 , ...,  0.38571906,\n",
       "         -0.12748194,  1.227637  ]],\n",
       "\n",
       "       [[-0.81431186,  0.38377762,  0.86045367, ...,  0.1744312 ,\n",
       "          0.07475193,  0.2109456 ],\n",
       "        [-0.81431186,  0.38377762,  0.86045367, ...,  0.1744312 ,\n",
       "          0.07475193,  0.2109456 ],\n",
       "        [-0.81431186,  0.38377762,  0.86045367, ...,  0.1744312 ,\n",
       "          0.07475193,  0.2109456 ],\n",
       "        ...,\n",
       "        [-0.81431186,  0.38377762,  0.86045367, ...,  0.1744312 ,\n",
       "          0.07475193,  0.2109456 ],\n",
       "        [-0.81431186,  0.38377762,  0.86045367, ...,  0.1744312 ,\n",
       "          0.07475193,  0.2109456 ],\n",
       "        [-0.81431186,  0.38377762,  0.86045367, ...,  0.1744312 ,\n",
       "          0.07475193,  0.2109456 ]],\n",
       "\n",
       "       [[-0.11332001,  0.71685886,  0.5253072 , ...,  0.3483342 ,\n",
       "          0.03288898,  0.09516512],\n",
       "        [-0.11332001,  0.71685886,  0.5253072 , ...,  0.3483342 ,\n",
       "          0.03288898,  0.09516512],\n",
       "        [-0.11332001,  0.71685886,  0.5253072 , ...,  0.3483342 ,\n",
       "          0.03288898,  0.09516512],\n",
       "        ...,\n",
       "        [-0.11332001,  0.71685886,  0.5253072 , ...,  0.3483342 ,\n",
       "          0.03288898,  0.09516512],\n",
       "        [-0.11332001,  0.71685886,  0.5253072 , ...,  0.3483342 ,\n",
       "          0.03288898,  0.09516512],\n",
       "        [-0.11332001,  0.71685886,  0.5253072 , ...,  0.3483342 ,\n",
       "          0.03288898,  0.09516512]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.7156823 , -0.3531897 ,  0.36759323, ...,  0.00661592,\n",
       "         -0.8199157 , -0.9023752 ],\n",
       "        [-0.7156823 , -0.3531897 ,  0.36759323, ...,  0.00661592,\n",
       "         -0.8199157 , -0.9023752 ],\n",
       "        [-0.7156823 , -0.3531897 ,  0.36759323, ...,  0.00661592,\n",
       "         -0.8199157 , -0.9023752 ],\n",
       "        ...,\n",
       "        [-0.7156823 , -0.3531897 ,  0.36759323, ...,  0.00661592,\n",
       "         -0.8199157 , -0.9023752 ],\n",
       "        [-0.7156823 , -0.3531897 ,  0.36759323, ...,  0.00661592,\n",
       "         -0.8199157 , -0.9023752 ],\n",
       "        [-0.7156823 , -0.3531897 ,  0.36759323, ...,  0.00661592,\n",
       "         -0.8199157 , -0.9023752 ]],\n",
       "\n",
       "       [[-0.49993604, -1.3083915 , -0.491055  , ...,  0.10118008,\n",
       "          0.145692  , -0.88524085],\n",
       "        [-0.49993604, -1.3083915 , -0.491055  , ...,  0.10118008,\n",
       "          0.145692  , -0.88524085],\n",
       "        [-0.49993604, -1.3083915 , -0.491055  , ...,  0.10118008,\n",
       "          0.145692  , -0.88524085],\n",
       "        ...,\n",
       "        [-0.49993604, -1.3083915 , -0.491055  , ...,  0.10118008,\n",
       "          0.145692  , -0.88524085],\n",
       "        [-0.49993604, -1.3083915 , -0.491055  , ...,  0.10118008,\n",
       "          0.145692  , -0.88524085],\n",
       "        [-0.49993604, -1.3083915 , -0.491055  , ...,  0.10118008,\n",
       "          0.145692  , -0.88524085]],\n",
       "\n",
       "       [[ 0.7450793 ,  0.7042922 , -0.23236   , ...,  0.15793459,\n",
       "          0.25966442,  0.21801814],\n",
       "        [ 0.7450793 ,  0.7042922 , -0.23236   , ...,  0.15793459,\n",
       "          0.25966442,  0.21801814],\n",
       "        [ 0.7450793 ,  0.7042922 , -0.23236   , ...,  0.15793459,\n",
       "          0.25966442,  0.21801814],\n",
       "        ...,\n",
       "        [ 0.7450793 ,  0.7042922 , -0.23236   , ...,  0.15793459,\n",
       "          0.25966442,  0.21801814],\n",
       "        [ 0.7450793 ,  0.7042922 , -0.23236   , ...,  0.15793459,\n",
       "          0.25966442,  0.21801814],\n",
       "        [ 0.7450793 ,  0.7042922 , -0.23236   , ...,  0.15793459,\n",
       "          0.25966442,  0.21801814]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt_concat_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39bd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
