{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f189f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import tensorrt as trt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c560b",
   "metadata": {},
   "source": [
    "## Generate input and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24dc161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "\n",
    "batch_size, seq_len, hidden_size = 4, 45, 4096\n",
    "intermediate_size = 11008\n",
    "num_attention_heads = 32\n",
    "num_key_value_heads = 32\n",
    "max_position_embeddings = 2048\n",
    "rope_theta = 10000.0\n",
    "\n",
    "config[\"hidden_size\"] = hidden_size\n",
    "config[\"intermediate_size\"] = intermediate_size\n",
    "config[\"num_heads\"] = num_attention_heads\n",
    "config[\"head_dim\"] = config[\"hidden_size\"] // config[\"num_heads\"]\n",
    "config[\"num_key_value_heads\"] = num_key_value_heads\n",
    "config[\"num_key_value_groups\"] = config[\"num_heads\"] // config[\"num_key_value_heads\"]\n",
    "config[\"max_position_embeddings\"] = max_position_embeddings\n",
    "config[\"rope_theta\"] = rope_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4deac14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(batch_size, seq_len, hidden_size)\n",
    "attention_mask = torch.ones(batch_size, 1, seq_len, seq_len)\n",
    "position_ids = torch.arange(0, seq_len)\n",
    "position_ids = position_ids.repeat(batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aedffd",
   "metadata": {},
   "source": [
    "## torch attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17fa64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n",
    "    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n",
    "    \n",
    "    repeat at the second dimension\n",
    "    \"\"\"\n",
    "    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
    "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db5e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaRotaryEmbedding(torch.nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2).float().to(device) / self.dim))\n",
    "        \n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "        t = torch.arange(max_position_embeddings, device=device, dtype=self.inv_freq.dtype)\n",
    "\n",
    "        freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "        # Different from paper, but it uses a different permutation in order to obtain the same calculation\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos()[None, None, :, :].to(torch.get_default_dtype()), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin()[None, None, :, :].to(torch.get_default_dtype()), persistent=False)\n",
    "\n",
    "    def rotate_half(self, x):\n",
    "        \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "        x1 = x[..., : x.shape[-1] // 2]\n",
    "        x2 = x[..., x.shape[-1] // 2 :]\n",
    "        return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, position_ids, seq_len=None):\n",
    "        # v: [bs, num_attention_heads, seq_len, head_size]\n",
    "        cos = self.cos_cached[:, :, :seq_len, ...].to(dtype=v.dtype)\n",
    "        sin = self.sin_cached[:, :, :seq_len, ...].to(dtype=v.dtype)\n",
    "        cos = cos.squeeze(1).squeeze(0)  # [seq_len, dim]\n",
    "        sin = sin.squeeze(1).squeeze(0)  # [seq_len, dim]\n",
    "        cos = cos[position_ids].unsqueeze(1)  # [bs, 1, seq_len, dim]\n",
    "        sin = sin[position_ids].unsqueeze(1)  # [bs, 1, seq_len, dim]\n",
    "\n",
    "        # The first two dimensions of cos and sin are always 1, so we can `squeeze` them.\n",
    "        q_embed = (q * cos) + (self.rotate_half(q) * sin)\n",
    "        k_embed = (k * cos) + (self.rotate_half(k) * sin)\n",
    "        return q_embed, k_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27151807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaAttention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        self.head_dim = config[\"hidden_size\"] // config[\"num_heads\"]\n",
    "        self.num_key_value_heads = config[\"num_key_value_heads\"]\n",
    "        self.num_key_value_groups = config[\"num_heads\"] // config[\"num_key_value_heads\"]\n",
    "        self.max_position_embeddings = config[\"max_position_embeddings\"]\n",
    "        self.rope_theta = config[\"rope_theta\"]\n",
    "\n",
    "        if (self.head_dim * self.num_heads) != self.hidden_size:\n",
    "            raise ValueError(\n",
    "                f\"hidden_size must be divisible by num_heads (got `hidden_size`: {self.hidden_size}\"\n",
    "                f\" and `num_heads`: {self.num_heads}).\"\n",
    "            )\n",
    "        self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=False)\n",
    "        self.k_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=False)\n",
    "        self.v_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=False)\n",
    "        self.o_proj = nn.Linear(self.num_heads * self.head_dim, self.hidden_size, bias=False)\n",
    "        self._init_rope()\n",
    "\n",
    "    def _init_rope(self):\n",
    "        print(\n",
    "            \"init rope\",\n",
    "            self.head_dim,\n",
    "            self.max_position_embeddings,\n",
    "            self.rope_theta,\n",
    "        )\n",
    "        self.rotary_emb = LlamaRotaryEmbedding(\n",
    "            self.head_dim,\n",
    "            max_position_embeddings=self.max_position_embeddings,\n",
    "            base=self.rope_theta,\n",
    "        )\n",
    "\n",
    "    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):\n",
    "        return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()\n",
    "\n",
    "\n",
    "    def load(self, dir):\n",
    "        weights = torch.load(dir)\n",
    "        self_attn_weights = dict()\n",
    "        for key in weights.keys():\n",
    "            print(key)\n",
    "            if key == \"model.layers.18.self_attn.rotary_emb.inv_freq\":\n",
    "                print(weights[key])\n",
    "                continue\n",
    "            if key.split(\".\")[3] == \"self_attn\":\n",
    "                self_attn_weights[key[key.find(key.split(\".\")[4]):]] = weights[key]\n",
    "\n",
    "        self.load_state_dict(self_attn_weights)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: None,\n",
    "        position_ids: None,\n",
    "        past_key_value: None,\n",
    "        output_attentions: bool = False,\n",
    "        use_cache: bool = False,\n",
    "    ):\n",
    "        # bsz = batch size; q_len = query length; _ = hidden size\n",
    "        bsz, q_len, _ = hidden_states.size()\n",
    "\n",
    "        # do projection\n",
    "        query_states = self.q_proj(hidden_states)\n",
    "        key_states = self.k_proj(hidden_states)\n",
    "        value_states = self.v_proj(hidden_states)\n",
    "\n",
    "        # reshape\n",
    "        query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "        value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "#         #####################################################\n",
    "#         # in hugging face, they do have kv cache, however, they don't have other attention optimization\n",
    "#         # this could be done directly in tensorRT by using dynamic shape\n",
    "#         kv_seq_len = key_states.shape[-2]\n",
    "#         if past_key_value is not None:\n",
    "#             kv_seq_len += past_key_value[0].shape[-2]\n",
    "\n",
    "#         query_states, key_states = self.rotary_emb(query_states, key_states, value_states, position_ids, seq_len=q_len)\n",
    "\n",
    "#         if past_key_value is not None:\n",
    "#             # reuse k, v, self_attention\n",
    "#             key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
    "#             value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
    "\n",
    "#         past_key_value = (key_states, value_states) if use_cache else None\n",
    "\n",
    "#         print(self.num_key_value_groups)\n",
    "#         # repeat k/v heads if n_kv_heads < n_heads\n",
    "#         key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "#         value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "#         #####################################################\n",
    "\n",
    "        attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        # attention_mask needs to be infered\n",
    "        attn_weights = attn_weights + attention_mask\n",
    "\n",
    "        # upcast attention to fp32\n",
    "        attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, value_states)\n",
    "\n",
    "        attn_output = attn_output.transpose(1, 2) # .contiguous()\n",
    "        attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)\n",
    "\n",
    "        attn_output = self.o_proj(attn_output)\n",
    "\n",
    "        return attn_output, attn_weights, None\n",
    "\n",
    "        # since normally it will be false\n",
    "#         if not output_attentions:\n",
    "#             attn_weights = None\n",
    "\n",
    "#         return attn_output, attn_weights, past_key_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637a49c",
   "metadata": {},
   "source": [
    "## Test torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd3e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init rope 128 2048 10000.0\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.rotary_emb.inv_freq\n",
      "tensor([1.0000e+00, 8.6596e-01, 7.4989e-01, 6.4938e-01, 5.6234e-01, 4.8697e-01,\n",
      "        4.2170e-01, 3.6517e-01, 3.1623e-01, 2.7384e-01, 2.3714e-01, 2.0535e-01,\n",
      "        1.7783e-01, 1.5399e-01, 1.3335e-01, 1.1548e-01, 1.0000e-01, 8.6596e-02,\n",
      "        7.4989e-02, 6.4938e-02, 5.6234e-02, 4.8697e-02, 4.2170e-02, 3.6517e-02,\n",
      "        3.1623e-02, 2.7384e-02, 2.3714e-02, 2.0535e-02, 1.7783e-02, 1.5399e-02,\n",
      "        1.3335e-02, 1.1548e-02, 1.0000e-02, 8.6596e-03, 7.4989e-03, 6.4938e-03,\n",
      "        5.6234e-03, 4.8697e-03, 4.2170e-03, 3.6517e-03, 3.1623e-03, 2.7384e-03,\n",
      "        2.3714e-03, 2.0535e-03, 1.7783e-03, 1.5399e-03, 1.3335e-03, 1.1548e-03,\n",
      "        1.0000e-03, 8.6596e-04, 7.4989e-04, 6.4938e-04, 5.6234e-04, 4.8697e-04,\n",
      "        4.2170e-04, 3.6517e-04, 3.1623e-04, 2.7384e-04, 2.3714e-04, 2.0535e-04,\n",
      "        1.7783e-04, 1.5399e-04, 1.3335e-04, 1.1548e-04])\n"
     ]
    }
   ],
   "source": [
    "model = LlamaAttention(config)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model.load(\"/home/fuchiang137/.cache/huggingface/hub/models--decapoda-research--llama-7b-hf/snapshots/5f98eefcc80e437ef68d457ad7bf167c2c6a1348/pytorch_model-00019-of-00033.bin\")\n",
    "model = model.to(device)\n",
    "\n",
    "data_D = data.to(device)\n",
    "attention_mask_D = attention_mask.to(device)\n",
    "position_ids_D = position_ids.to(device)\n",
    "# output = model(data)\n",
    "\n",
    "past_key_value = None\n",
    "\n",
    "# attentiona mask\n",
    "# position_ids\n",
    "# specifies the position id of the corresponding hidden state tensor element\n",
    "# e.g. hid = [3, 4, 6] => pos_id = [0, 1, 2]\n",
    "# past_key_value\n",
    "# if use cache, past key value will contain past kv values\n",
    "output = model(hidden_states=data_D,\n",
    "               attention_mask=attention_mask_D,\n",
    "               position_ids=position_ids_D,\n",
    "               past_key_value=past_key_value,\n",
    "               output_attentions=False,\n",
    "               use_cache=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a068ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_weights, past_key_value = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9223cd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 45, 4096])\n",
      "tensor([[-0.3422, -1.3077,  3.2849,  ..., -1.2631, -0.5749,  1.4960],\n",
      "        [-0.3422, -1.3077,  3.2849,  ..., -1.2631, -0.5749,  1.4960],\n",
      "        [-0.3422, -1.3077,  3.2849,  ..., -1.2631, -0.5749,  1.4960],\n",
      "        ...,\n",
      "        [-0.3422, -1.3077,  3.2849,  ..., -1.2631, -0.5749,  1.4960],\n",
      "        [-0.3422, -1.3077,  3.2849,  ..., -1.2631, -0.5749,  1.4960],\n",
      "        [-0.3422, -1.3077,  3.2849,  ..., -1.2631, -0.5749,  1.4960]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attn_output.shape)\n",
    "print(attn_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e76bcef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 45, 45])\n",
      "tensor([[[0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         ...,\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222]],\n",
      "\n",
      "        [[0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         ...,\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222]],\n",
      "\n",
      "        [[0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         ...,\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         ...,\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222]],\n",
      "\n",
      "        [[0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         ...,\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222]],\n",
      "\n",
      "        [[0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         ...,\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222],\n",
      "         [0.0222, 0.0222, 0.0222,  ..., 0.0222, 0.0222, 0.0222]]],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(attn_weights.shape)\n",
    "print(attn_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f5cb596",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(past_key_value[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(past_key_value.shape)\n",
    "print(past_key_value[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bcfed",
   "metadata": {},
   "source": [
    "## Breaking down LlamaRotaryEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd07fc7",
   "metadata": {},
   "source": [
    "## tensorRT Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abec6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq length is not specified, since it is a dynamic size\n",
    "def trt_create(batch_size, hidden_size, intermediate_size, model):\n",
    "    \n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # input\n",
    "    hidden_states = network.add_input('hidden_states', trt.DataType.FLOAT, (batch_size, -1, hidden_size))\n",
    "    attention_mask = network.add_input('attention_mask', trt.DataType.FLOAT, (batch_size, 1, -1, -1))\n",
    "\n",
    "    # dynamic shape optimization\n",
    "    profile = builder.create_optimization_profile();\n",
    "    profile.set_shape(\"hidden_states\", (batch_size, 1, hidden_size), (batch_size, 1, hidden_size), (batch_size, 45, hidden_size))\n",
    "    profile.set_shape(\"attention_mask\", (batch_size, 1, 1, 1), (batch_size, 1, 1, 1), (batch_size, 1, 45, 45))\n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "    # self.q_proj(hidden_states)\n",
    "    q_proj_weight = model.q_proj.weight.clone().detach().cpu().numpy()\n",
    "    q_proj_weight = np.expand_dims(q_proj_weight, 0)\n",
    "    q_proj_weight_shape = list(q_proj_weight.shape)\n",
    "    q_proj_weight_layer = network.add_constant(shape=q_proj_weight_shape, weights=trt.Weights(q_proj_weight))\n",
    "\n",
    "    q_proj_layer = network.add_matrix_multiply(hidden_states,\n",
    "                                               trt.MatrixOperation.NONE,\n",
    "                                               q_proj_weight_layer.get_output(0),\n",
    "                                               trt.MatrixOperation.TRANSPOSE)\n",
    "\n",
    "    # query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "    q_proj_shuffle_layer = network.add_shuffle(q_proj_layer.get_output(0))\n",
    "    q_proj_shuffle_layer.reshape_dims = trt.Dims([batch_size, -1, model.num_heads, model.head_dim])\n",
    "    q_proj_shuffle_layer.second_transpose = trt.Permutation([0, 2, 1, 3])\n",
    "\n",
    "    \n",
    "    # self.k_proj(hidden_states)\n",
    "    k_proj_weight = model.k_proj.weight.clone().detach().cpu().numpy()\n",
    "    k_proj_weight = np.expand_dims(k_proj_weight, 0)\n",
    "    k_proj_weight_shape = list(k_proj_weight.shape)\n",
    "    k_proj_weight_layer = network.add_constant(shape=k_proj_weight_shape, weights=trt.Weights(k_proj_weight))\n",
    "\n",
    "    k_proj_layer = network.add_matrix_multiply(hidden_states,\n",
    "                                               trt.MatrixOperation.NONE,\n",
    "                                               k_proj_weight_layer.get_output(0),\n",
    "                                               trt.MatrixOperation.TRANSPOSE)\n",
    "\n",
    "    # key_states = key_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "    k_proj_shuffle_layer = network.add_shuffle(k_proj_layer.get_output(0))\n",
    "    k_proj_shuffle_layer.reshape_dims = trt.Dims([batch_size, -1, model.num_heads, model.head_dim])\n",
    "    k_proj_shuffle_layer.second_transpose = trt.Permutation([0, 2, 3, 1])\n",
    "\n",
    "\n",
    "    # self.v_proj(hidden_states)\n",
    "    v_proj_weight = model.v_proj.weight.clone().detach().cpu().numpy()\n",
    "    v_proj_weight = np.expand_dims(v_proj_weight, 0)\n",
    "    v_proj_weight_shape = list(v_proj_weight.shape)\n",
    "    v_proj_weight_layer = network.add_constant(shape=v_proj_weight_shape, weights=trt.Weights(v_proj_weight))\n",
    "\n",
    "    v_proj_layer = network.add_matrix_multiply(hidden_states,\n",
    "                                               trt.MatrixOperation.NONE,\n",
    "                                               v_proj_weight_layer.get_output(0),\n",
    "                                               trt.MatrixOperation.TRANSPOSE)\n",
    "\n",
    "    # value_states = value_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "    v_proj_shuffle_layer = network.add_shuffle(v_proj_layer.get_output(0))\n",
    "    v_proj_shuffle_layer.reshape_dims = trt.Dims([batch_size, -1, model.num_heads, model.head_dim])\n",
    "    v_proj_shuffle_layer.second_transpose = trt.Permutation([0, 2, 1, 3])\n",
    "\n",
    "    # attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "    attn_weights_mult_layer = network.add_matrix_multiply(q_proj_shuffle_layer.get_output(0),\n",
    "                                                          trt.MatrixOperation.NONE,\n",
    "                                                          k_proj_shuffle_layer.get_output(0),\n",
    "                                                          trt.MatrixOperation.NONE)\n",
    "\n",
    "    sqrt_head_dim = np.array([1 / math.sqrt(model.head_dim)], np.float32).reshape(-1)\n",
    "    attn_weights_layer = network.add_scale(attn_weights_mult_layer.get_output(0),\n",
    "                                           trt.ScaleMode.UNIFORM,\n",
    "                                           scale=sqrt_head_dim)\n",
    "\n",
    "    # attn_weights = attn_weights + attention_mask\n",
    "    attn_mix_mask = network.add_elementwise(attn_weights_layer.get_output(0),\n",
    "                                            attention_mask,\n",
    "                                            op=trt.ElementWiseOperation.SUM)\n",
    "\n",
    "    # attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
    "    softmax_layer = network.add_softmax(attn_mix_mask.get_output(0))\n",
    "    softmax_layer.axes = 1 << 3\n",
    "\n",
    "    # attn_output = torch.matmul(attn_weights, value_states)\n",
    "    attn_output_layer = network.add_matrix_multiply(softmax_layer.get_output(0),\n",
    "                                                    trt.MatrixOperation.NONE,\n",
    "                                                    v_proj_shuffle_layer.get_output(0),\n",
    "                                                    trt.MatrixOperation.NONE)\n",
    "\n",
    "    # attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "    # attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)\n",
    "    attn_output_shuffle_layer = network.add_shuffle(attn_output_layer.get_output(0))\n",
    "    attn_output_shuffle_layer.first_transpose = trt.Permutation([0, 2, 1, 3])\n",
    "    attn_output_shuffle_layer.reshape_dims = trt.Dims([batch_size, -1, hidden_size])\n",
    "\n",
    "    # attn_output = self.o_proj(attn_output)\n",
    "    o_proj_weight = model.o_proj.weight.clone().detach().cpu().numpy()\n",
    "    o_proj_weight = np.expand_dims(o_proj_weight, 0)\n",
    "    o_proj_weight_shape = list(o_proj_weight.shape)\n",
    "    o_proj_weight_layer = network.add_constant(shape=o_proj_weight_shape, weights=trt.Weights(o_proj_weight))\n",
    "    \n",
    "    o_proj_layer = network.add_matrix_multiply(attn_output_shuffle_layer.get_output(0),\n",
    "                                               trt.MatrixOperation.NONE,\n",
    "                                               o_proj_weight_layer.get_output(0),\n",
    "                                               trt.MatrixOperation.TRANSPOSE)\n",
    "\n",
    "    # output\n",
    "    # the order of output will be related to the order of the tensor creation\n",
    "    network.mark_output(softmax_layer.get_output(0))\n",
    "    network.mark_output(o_proj_layer.get_output(0))\n",
    "    network.mark_output(v_proj_shuffle_layer.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d10fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_engineStr = trt_create(batch_size, hidden_size, intermediate_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e1b2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(batch_size, hidden_size, engineString, raw_data, raw_attn_mask):\n",
    "#     print(engineString)\n",
    "#     print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "    print(\"Set input shape\", (batch_size, seq_len, hidden_size))\n",
    "\n",
    "    context.set_input_shape(\"hidden_states\", (batch_size, seq_len, hidden_size))\n",
    "    context.set_binding_shape(0, (batch_size, seq_len, hidden_size))\n",
    "\n",
    "    context.set_input_shape(\"attention_mask\", (batch_size, 1, seq_len, seq_len))\n",
    "    context.set_binding_shape(1, (batch_size, 1, seq_len, seq_len))\n",
    "    print(\"Set input shape completed\")\n",
    "\n",
    "    data = np.array(raw_data)\n",
    "    attention_mask = np.array(raw_attn_mask)\n",
    "\n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "#     print(\"Reshaping\")\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(data.reshape(-1))\n",
    "    inputH1 = np.ascontiguousarray(attention_mask.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
    "    outputH1 = np.empty(context.get_binding_shape(3), dtype=trt.nptype(engine.get_binding_dtype(3)))\n",
    "    outputH2 = np.empty(context.get_binding_shape(4), dtype=trt.nptype(engine.get_binding_dtype(4)))\n",
    "#     print(\"Reshaped\")\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, inputD1 = cudart.cudaMallocAsync(inputH1.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "    _, outputD1 = cudart.cudaMallocAsync(outputH1.nbytes, stream)\n",
    "    _, outputD2 = cudart.cudaMallocAsync(outputH2.nbytes, stream)\n",
    "\n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "    cudart.cudaMemcpyAsync(inputD1, inputH1.ctypes.data, inputH1.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "\n",
    "    # execute\n",
    "#     print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(inputD1), int(outputD0), int(outputD1), int(outputD2)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "    cudart.cudaMemcpyAsync(outputH1.ctypes.data, outputD1, outputH1.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "    cudart.cudaMemcpyAsync(outputH2.ctypes.data, outputD2, outputH2.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "\n",
    "    # wait for everythidden_sizeg\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(outputD0)\n",
    "    cudart.cudaFree(outputD1)\n",
    "    cudart.cudaFree(outputD2)\n",
    "\n",
    "    return outputH0, outputH1, outputH2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a999ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set input shape (4, 45, 4096)\n",
      "Set input shape completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_655/2974348848.py:12: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(0, (batch_size, seq_len, hidden_size))\n",
      "/tmp/ipykernel_655/2974348848.py:15: DeprecationWarning: Use set_input_shape instead.\n",
      "  context.set_binding_shape(1, (batch_size, 1, seq_len, seq_len))\n",
      "/tmp/ipykernel_655/2974348848.py:26: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
      "/tmp/ipykernel_655/2974348848.py:26: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(2), dtype=trt.nptype(engine.get_binding_dtype(2)))\n",
      "/tmp/ipykernel_655/2974348848.py:27: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH1 = np.empty(context.get_binding_shape(3), dtype=trt.nptype(engine.get_binding_dtype(3)))\n",
      "/tmp/ipykernel_655/2974348848.py:27: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH1 = np.empty(context.get_binding_shape(3), dtype=trt.nptype(engine.get_binding_dtype(3)))\n",
      "/tmp/ipykernel_655/2974348848.py:28: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH2 = np.empty(context.get_binding_shape(4), dtype=trt.nptype(engine.get_binding_dtype(4)))\n",
      "/tmp/ipykernel_655/2974348848.py:28: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH2 = np.empty(context.get_binding_shape(4), dtype=trt.nptype(engine.get_binding_dtype(4)))\n"
     ]
    }
   ],
   "source": [
    "trt_output = trt_inference(batch_size, hidden_size, trt_engineStr, data, attention_mask)\n",
    "\n",
    "trt_query_states, trt_key_states, trt_value_states = trt_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b513c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32, 45, 128)\n",
      "[[[-0.7616343  -0.32004273  0.5074545  ...  0.8154828   1.3458583\n",
      "    1.7691885 ]\n",
      "  [-0.7616343  -0.32004273  0.5074545  ...  0.8154828   1.3458583\n",
      "    1.7691885 ]\n",
      "  [-0.7616343  -0.32004273  0.5074545  ...  0.8154828   1.3458583\n",
      "    1.7691885 ]\n",
      "  ...\n",
      "  [-0.7616343  -0.32004273  0.5074545  ...  0.8154828   1.3458583\n",
      "    1.7691885 ]\n",
      "  [-0.7616343  -0.32004273  0.5074545  ...  0.8154828   1.3458583\n",
      "    1.7691885 ]\n",
      "  [-0.7616343  -0.32004273  0.5074545  ...  0.8154828   1.3458583\n",
      "    1.7691885 ]]\n",
      "\n",
      " [[ 2.1507761   0.6692885   3.2076879  ...  1.4208608   0.12534922\n",
      "    0.04899704]\n",
      "  [ 2.1507761   0.6692885   3.2076879  ...  1.4208608   0.12534922\n",
      "    0.04899704]\n",
      "  [ 2.1507761   0.6692885   3.2076879  ...  1.4208608   0.12534922\n",
      "    0.04899704]\n",
      "  ...\n",
      "  [ 2.1507761   0.6692885   3.2076879  ...  1.4208608   0.12534922\n",
      "    0.04899704]\n",
      "  [ 2.1507761   0.6692885   3.2076879  ...  1.4208608   0.12534922\n",
      "    0.04899704]\n",
      "  [ 2.1507761   0.6692885   3.2076879  ...  1.4208608   0.12534922\n",
      "    0.04899704]]\n",
      "\n",
      " [[ 0.53544754  0.4022442   1.419313   ...  0.7243541  -0.07933033\n",
      "    0.28675437]\n",
      "  [ 0.53544754  0.4022442   1.419313   ...  0.7243541  -0.07933033\n",
      "    0.28675437]\n",
      "  [ 0.53544754  0.4022442   1.419313   ...  0.7243541  -0.07933033\n",
      "    0.28675437]\n",
      "  ...\n",
      "  [ 0.53544754  0.4022442   1.419313   ...  0.7243541  -0.07933033\n",
      "    0.28675437]\n",
      "  [ 0.53544754  0.4022442   1.419313   ...  0.7243541  -0.07933033\n",
      "    0.28675437]\n",
      "  [ 0.53544754  0.4022442   1.419313   ...  0.7243541  -0.07933033\n",
      "    0.28675437]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.9793105  -0.3205272  -0.963726   ...  1.7677937   0.2463702\n",
      "   -1.6139519 ]\n",
      "  [ 2.9793105  -0.3205272  -0.963726   ...  1.7677937   0.2463702\n",
      "   -1.6139519 ]\n",
      "  [ 2.9793105  -0.3205272  -0.963726   ...  1.7677937   0.2463702\n",
      "   -1.6139519 ]\n",
      "  ...\n",
      "  [ 2.9793105  -0.3205272  -0.963726   ...  1.7677937   0.2463702\n",
      "   -1.6139519 ]\n",
      "  [ 2.9793105  -0.3205272  -0.963726   ...  1.7677937   0.2463702\n",
      "   -1.6139519 ]\n",
      "  [ 2.9793105  -0.3205272  -0.963726   ...  1.7677937   0.2463702\n",
      "   -1.6139519 ]]\n",
      "\n",
      " [[-1.0813383   0.5821409   0.899631   ... -0.2767951   3.6704144\n",
      "   -0.8123876 ]\n",
      "  [-1.0813383   0.5821409   0.899631   ... -0.2767951   3.6704144\n",
      "   -0.8123876 ]\n",
      "  [-1.0813383   0.5821409   0.899631   ... -0.2767951   3.6704144\n",
      "   -0.8123876 ]\n",
      "  ...\n",
      "  [-1.0813383   0.5821409   0.899631   ... -0.2767951   3.6704144\n",
      "   -0.8123876 ]\n",
      "  [-1.0813383   0.5821409   0.899631   ... -0.2767951   3.6704144\n",
      "   -0.8123876 ]\n",
      "  [-1.0813383   0.5821409   0.899631   ... -0.2767951   3.6704144\n",
      "   -0.8123876 ]]\n",
      "\n",
      " [[ 0.10648263 -0.29485744  0.42041326 ... -1.2552826   0.07160676\n",
      "   -0.6232966 ]\n",
      "  [ 0.10648263 -0.29485744  0.42041326 ... -1.2552826   0.07160676\n",
      "   -0.6232966 ]\n",
      "  [ 0.10648263 -0.29485744  0.42041326 ... -1.2552826   0.07160676\n",
      "   -0.6232966 ]\n",
      "  ...\n",
      "  [ 0.10648263 -0.29485744  0.42041326 ... -1.2552826   0.07160676\n",
      "   -0.6232966 ]\n",
      "  [ 0.10648263 -0.29485744  0.42041326 ... -1.2552826   0.07160676\n",
      "   -0.6232966 ]\n",
      "  [ 0.10648263 -0.29485744  0.42041326 ... -1.2552826   0.07160676\n",
      "   -0.6232966 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(trt_query_states.shape)\n",
    "print(trt_query_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09bbb643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32, 45, 45)\n",
      "[[[0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  ...\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]]\n",
      "\n",
      " [[0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  ...\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]]\n",
      "\n",
      " [[0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  ...\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  ...\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]]\n",
      "\n",
      " [[0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  ...\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]]\n",
      "\n",
      " [[0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  ...\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]\n",
      "  [0.02222222 0.02222222 0.02222222 ... 0.02222222 0.02222222 0.02222222]]]\n"
     ]
    }
   ],
   "source": [
    "print(trt_key_states.shape)\n",
    "print(trt_key_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77b14a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 45, 4096)\n",
      "[[-0.342221   -1.3077192   3.2848744  ... -1.263129   -0.57490236\n",
      "   1.4959995 ]\n",
      " [-0.342221   -1.3077192   3.2848744  ... -1.263129   -0.57490236\n",
      "   1.4959995 ]\n",
      " [-0.342221   -1.3077192   3.2848744  ... -1.263129   -0.57490236\n",
      "   1.4959995 ]\n",
      " ...\n",
      " [-0.342221   -1.3077192   3.2848744  ... -1.263129   -0.57490236\n",
      "   1.4959995 ]\n",
      " [-0.342221   -1.3077192   3.2848744  ... -1.263129   -0.57490236\n",
      "   1.4959995 ]\n",
      " [-0.342221   -1.3077192   3.2848744  ... -1.263129   -0.57490236\n",
      "   1.4959995 ]]\n"
     ]
    }
   ],
   "source": [
    "print(trt_value_states.shape)\n",
    "print(trt_value_states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4189b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
