{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e77da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cuda import cudart\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import tensorrt as trt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297abd5",
   "metadata": {},
   "source": [
    "## Generate input and data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce9554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "\n",
    "batch_size, seq_len, hidden_size = 4, 45, 4096\n",
    "intermediate_size = 11008\n",
    "num_attention_heads = 32\n",
    "num_key_value_heads = 32\n",
    "max_position_embeddings = 2048\n",
    "rope_theta = 10000.0\n",
    "\n",
    "config[\"hidden_size\"] = hidden_size\n",
    "config[\"intermediate_size\"] = intermediate_size\n",
    "config[\"num_heads\"] = num_attention_heads\n",
    "config[\"head_dim\"] = config[\"hidden_size\"] // config[\"num_heads\"]\n",
    "config[\"num_key_value_heads\"] = num_key_value_heads\n",
    "config[\"num_key_value_groups\"] = config[\"num_heads\"] // config[\"num_key_value_heads\"]\n",
    "config[\"max_position_embeddings\"] = max_position_embeddings\n",
    "config[\"rope_theta\"] = rope_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d882847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.ones(batch_size, seq_len, hidden_size)\n",
    "attention_mask=torch.ones(batch_size, 1, seq_len, seq_len)\n",
    "position_ids = torch.arange(0, seq_len)\n",
    "position_ids = position_ids.repeat(batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb39a8",
   "metadata": {},
   "source": [
    "## torch attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e95b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n",
    "    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n",
    "    \n",
    "    repeat at the second dimension\n",
    "    \"\"\"\n",
    "    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
    "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "205d3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaRotaryEmbedding(torch.nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=2048, base=10000, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        print(torch.arange(0, 20, 2))\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2).float().to(device) / self.dim))\n",
    "        \n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "\n",
    "        t = torch.arange(max_position_embeddings, device=device, dtype=self.inv_freq.dtype)\n",
    "\n",
    "        freqs = torch.einsum(\"i,j->ij\", t, self.inv_freq)\n",
    "        # Different from paper, but it uses a different permutation in order to obtain the same calculation\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos()[None, None, :, :].to(torch.get_default_dtype()), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin()[None, None, :, :].to(torch.get_default_dtype()), persistent=False)\n",
    "\n",
    "    def rotate_half(self, x):\n",
    "        \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "        x1 = x[..., : x.shape[-1] // 2]\n",
    "        x2 = x[..., x.shape[-1] // 2 :]\n",
    "        return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "    def forward(self, q, k, v, position_ids, seq_len=None):\n",
    "        # v: [bs, num_attention_heads, seq_len, head_size]\n",
    "        cos = self.cos_cached[:, :, :seq_len, ...].to(dtype=v.dtype)\n",
    "        sin = self.sin_cached[:, :, :seq_len, ...].to(dtype=v.dtype)\n",
    "        cos = cos.squeeze(1).squeeze(0)  # [seq_len, dim]\n",
    "        sin = sin.squeeze(1).squeeze(0)  # [seq_len, dim]\n",
    "        cos = cos[position_ids].unsqueeze(1)  # [bs, 1, seq_len, dim]\n",
    "        sin = sin[position_ids].unsqueeze(1)  # [bs, 1, seq_len, dim]\n",
    "\n",
    "        # The first two dimensions of cos and sin are always 1, so we can `squeeze` them.\n",
    "        q_embed = (q * cos) + (self.rotate_half(q) * sin)\n",
    "        k_embed = (k * cos) + (self.rotate_half(k) * sin)\n",
    "        return q_embed, k_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "37020a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n",
      "tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]]])\n",
      "torch.Size([4, 32, 45, 128])\n",
      "tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]]])\n",
      "torch.Size([4, 32, 45, 128])\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 4\n",
    "test_seq_len = 45\n",
    "test_dim = 128\n",
    "test_max_position_embeddings = 2048\n",
    "\n",
    "rotary_emb = LlamaRotaryEmbedding(test_dim, test_max_position_embeddings, 10000.0)\n",
    "\n",
    "\n",
    "query_states = torch.ones(test_batch_size, 32, test_seq_len, test_dim)\n",
    "key_states = torch.ones(test_batch_size, 32, test_seq_len, test_dim)\n",
    "value_states = torch.ones(test_batch_size, 32, test_seq_len, test_dim)\n",
    "position_ids = torch.arange(test_seq_len).repeat(test_batch_size, 1)\n",
    "\n",
    "query_states, key_states = rotary_emb(query_states, key_states, value_states, position_ids, seq_len=test_seq_len)\n",
    "\n",
    "print(query_states[0])\n",
    "print(query_states.shape)\n",
    "print(key_states[0])\n",
    "print(key_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0067897e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 45, 128]) torch.Size([4, 1, 45, 128])\n",
      "tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]]])\n",
      "torch.Size([4, 32, 45, 128])\n",
      "tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]],\n",
      "\n",
      "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.3012, -0.1138,  0.0502,  ...,  1.0002,  1.0001,  1.0001],\n",
      "         [-1.3254, -1.1475, -0.9265,  ...,  1.0003,  1.0003,  1.0002],\n",
      "         ...,\n",
      "         [ 0.5165,  1.2106,  0.9173,  ...,  1.0064,  1.0056,  1.0048],\n",
      "         [ 1.3869,  1.3412, -0.0624,  ...,  1.0066,  1.0057,  1.0050],\n",
      "         [ 0.9821,  0.5273, -1.0086,  ...,  1.0068,  1.0059,  1.0051]]])\n",
      "torch.Size([4, 32, 45, 128])\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 4\n",
    "test_seq_len = 45\n",
    "test_dim = 128\n",
    "test_max_position_embeddings = 2048\n",
    "\n",
    "rotary_emb = LlamaRotaryEmbedding(test_dim, test_max_position_embeddings, 10000.0)\n",
    "\n",
    "\n",
    "query_states = torch.ones(test_batch_size, 32, test_seq_len, test_dim)\n",
    "key_states = torch.ones(test_batch_size, 32, test_seq_len, test_dim)\n",
    "value_states = torch.ones(test_batch_size, 32, test_seq_len, test_dim)\n",
    "position_ids = torch.arange(test_seq_len).repeat(test_batch_size, 1)\n",
    "\n",
    "cos, sin = rotary_emb(value_states, seq_len=test_seq_len)\n",
    "query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)\n",
    "\n",
    "print(query_states[0])\n",
    "print(query_states.shape)\n",
    "print(key_states[0])\n",
    "print(key_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514787ad",
   "metadata": {},
   "source": [
    "## Breaking down LlamaRotaryEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a4876f",
   "metadata": {},
   "source": [
    "## tensorRT MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cc6bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq length is not specified, since it is a dynamic size\n",
    "def trt_create(batch_size, hidden_size, intermediate_size):\n",
    "    \n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # input\n",
    "    inputT0 = network.add_input('inputT0', trt.DataType.FLOAT, (4, 4, 4))\n",
    "    \n",
    "#     network.mark_output(layer.get_output(0))\n",
    "\n",
    "    # dynamic shape optimization\n",
    "#     profile = builder.create_optimization_profile();\n",
    "#     profile.set_shape(\"inputT0\", (batch_size, 1,4), (batch_size, 1, 2, hidden_size), (batch_size, 1, 3, hidden_size))\n",
    "#     config.add_optimization_profile(profile)\n",
    "\n",
    "    slice_layer = network.add_slice(inputT0, start=(0, 0, 0), shape=inputT0.shape, stride=(1, 1, 1))\n",
    "\n",
    "#     # self.up_proj(x)\n",
    "#     up_proj_weight = model.up_proj.weight.clone().detach().cpu().numpy()\n",
    "#     up_proj_layer = network.add_fully_connected(inputT0, model.intermediate_size, up_proj_weight)\n",
    "\n",
    "#     # act_fn(self.gate_proj(x))\n",
    "#     gate_proj_weight = model.gate_proj.weight.clone().detach().cpu().numpy()\n",
    "#     gate_proj_layer = network.add_fully_connected(inputT0, model.intermediate_size, gate_proj_weight)\n",
    "\n",
    "#     selu_sigmoid_layer = network.add_activation(gate_proj_layer.get_output(0), type=trt.ActivationType.SIGMOID)\n",
    "#     selu_mult_layer = network.add_elementwise(gate_proj_layer.get_output(0), selu_sigmoid_layer.get_output(0), op=trt.ElementWiseOperation.PROD)\n",
    "\n",
    "#     # act_fn(self.gate_proj(x)) * self.up_proj(x)\n",
    "#     before_down_proj_layer = network.add_elementwise(selu_mult_layer.get_output(0), up_proj_layer.get_output(0), op=trt.ElementWiseOperation.PROD)\n",
    "\n",
    "#     down_proj_weight = model.down_proj.weight.clone().detach().cpu().numpy()\n",
    "#     down_proj_layer = network.add_fully_connected(before_down_proj_layer.get_output(0), hidden_size, down_proj_weight)\n",
    "\n",
    "    # output\n",
    "    network.mark_output(slice_layer.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56c61cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_engineStr = trt_create(batch_size, hidden_size, intermediate_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25aef4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(batch_size, hidden_size, engineString, raw_data):\n",
    "#     print(engineString)\n",
    "#     print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "#     print(\"Set input shape\", (batch_size, 1, hidden_size))\n",
    "#     context.set_input_shape(\"inputT0\", (batch_size, 1, hidden_size))\n",
    "#     context.set_binding_shape(0, (batch_size, 1, hidden_size))\n",
    "#     origin_inputshape = context.get_binding_shape(0)\n",
    "\n",
    "#     print(\"Set input shape completed\")\n",
    "\n",
    "    data = np.array(raw_data)\n",
    "\n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "#     print(\"Reshaping\")\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
    "#     print(\"Reshaped\")\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "\n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "\n",
    "    # execute\n",
    "#     print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(outputD0)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "\n",
    "    # wait for everythidden_sizeg\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(outputD0)\n",
    "\n",
    "    return outputH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3976d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]],\n",
      "\n",
      "        [[16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.]],\n",
      "\n",
      "        [[32., 33., 34., 35.],\n",
      "         [36., 37., 38., 39.],\n",
      "         [40., 41., 42., 43.],\n",
      "         [44., 45., 46., 47.]],\n",
      "\n",
      "        [[48., 49., 50., 51.],\n",
      "         [52., 53., 54., 55.],\n",
      "         [56., 57., 58., 59.],\n",
      "         [60., 61., 62., 63.]]])\n",
      "output_trt : (4, 4, 4)\n",
      "[[[ 0.  1.  2.  3.]\n",
      "  [ 4.  5.  6.  7.]\n",
      "  [ 8.  9. 10. 11.]\n",
      "  [12. 13. 14. 15.]]\n",
      "\n",
      " [[16. 17. 18. 19.]\n",
      "  [20. 21. 22. 23.]\n",
      "  [24. 25. 26. 27.]\n",
      "  [28. 29. 30. 31.]]\n",
      "\n",
      " [[32. 33. 34. 35.]\n",
      "  [36. 37. 38. 39.]\n",
      "  [40. 41. 42. 43.]\n",
      "  [44. 45. 46. 47.]]\n",
      "\n",
      " [[48. 49. 50. 51.]\n",
      "  [52. 53. 54. 55.]\n",
      "  [56. 57. 58. 59.]\n",
      "  [60. 61. 62. 63.]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31084/1007095647.py:22: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
      "/tmp/ipykernel_31084/1007095647.py:22: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n"
     ]
    }
   ],
   "source": [
    "# up_proj_weight = model.up_proj.weight.clone().detach().cpu().numpy()\n",
    "another_data = torch.arange(4 * 4 * 4, dtype=torch.float).reshape(4,4, 4)\n",
    "print(another_data)\n",
    "\n",
    "trt_output = trt_inference(batch_size, hidden_size, trt_engineStr, another_data)\n",
    "\n",
    "# trt_output = trt_output.reshape(batch_size, seq_len, hidden_size)\n",
    "print(\"output_trt :\", trt_output.shape)\n",
    "print(trt_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "49396539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaAttention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        self.head_dim = config[\"hidden_size\"] // config[\"num_heads\"]\n",
    "        self.num_key_value_heads = config[\"num_key_value_heads\"]\n",
    "        self.num_key_value_groups = config[\"num_heads\"] // config[\"num_key_value_heads\"]\n",
    "        self.max_position_embeddings = config[\"max_position_embeddings\"]\n",
    "        self.rope_theta = config[\"rope_theta\"]\n",
    "\n",
    "        if (self.head_dim * self.num_heads) != self.hidden_size:\n",
    "            raise ValueError(\n",
    "                f\"hidden_size must be divisible by num_heads (got `hidden_size`: {self.hidden_size}\"\n",
    "                f\" and `num_heads`: {self.num_heads}).\"\n",
    "            )\n",
    "        self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=False)\n",
    "        self.k_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=False)\n",
    "        self.v_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=False)\n",
    "        self.o_proj = nn.Linear(self.num_heads * self.head_dim, self.hidden_size, bias=False)\n",
    "        self._init_rope()\n",
    "\n",
    "    def _init_rope(self):\n",
    "        print(\n",
    "            \"init rope\",\n",
    "            self.head_dim,\n",
    "            self.max_position_embeddings,\n",
    "            self.rope_theta,\n",
    "        )\n",
    "        self.rotary_emb = LlamaRotaryEmbedding(\n",
    "            self.head_dim,\n",
    "            max_position_embeddings=self.max_position_embeddings,\n",
    "            base=self.rope_theta,\n",
    "        )\n",
    "\n",
    "    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):\n",
    "        return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: None,\n",
    "        position_ids: None,\n",
    "        past_key_value: None,\n",
    "        output_attentions: bool = False,\n",
    "        use_cache: bool = False,\n",
    "    ):\n",
    "        # bsz = batch size; q_len = query length; _ = hidden size\n",
    "        bsz, q_len, _ = hidden_states.size()\n",
    "\n",
    "        # do projection\n",
    "        query_states = self.q_proj(hidden_states)\n",
    "        key_states = self.k_proj(hidden_states)\n",
    "        value_states = self.v_proj(hidden_states)\n",
    "\n",
    "        # reshape\n",
    "        query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "        value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "\n",
    "        # in hugging face, they do have kv cache, however, they don't have other attention optimization\n",
    "        # this could be done directly in tensorRT by using dynamic shape\n",
    "        kv_seq_len = key_states.shape[-2]\n",
    "        if past_key_value is not None:\n",
    "            print(\"past_key_value is not None, kv_seq_len\")\n",
    "            kv_seq_len += past_key_value[0].shape[-2]\n",
    "\n",
    "        print(query_states.shape)\n",
    "        print(key_states.shape)\n",
    "        print(value_states.shape)\n",
    "\n",
    "\n",
    "        print(\"kv_seq_len\", kv_seq_len, position_ids)\n",
    "        query_states, key_states = rotary_emb(query_states, key_states, value_states, position_ids, seq_len=test_seq_len)\n",
    "\n",
    "\n",
    "        #####################################################\n",
    "\n",
    "        if past_key_value is not None:\n",
    "            print(\"past_key_value is not None, self_attention\")\n",
    "            # reuse k, v, self_attention\n",
    "            key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
    "            value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
    "\n",
    "        #####################################################\n",
    "\n",
    "        past_key_value = (key_states, value_states) if use_cache else None\n",
    "\n",
    "        print(self.num_key_value_groups)\n",
    "        # repeat k/v heads if n_kv_heads < n_heads\n",
    "        key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "        value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
    "\n",
    "        attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        attn_weights = attn_weights + attention_mask\n",
    "\n",
    "        # upcast attention to fp32\n",
    "        attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
    "        attn_output = torch.matmul(attn_weights, value_states)\n",
    "\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous()\n",
    "        attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)\n",
    "\n",
    "        attn_output = self.o_proj(attn_output)\n",
    "\n",
    "        if not output_attentions:\n",
    "            attn_weights = None\n",
    "\n",
    "        return attn_output, attn_weights, past_key_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9a24b",
   "metadata": {},
   "source": [
    "## Test torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "76881a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init rope 128 2048 10000.0\n",
      "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n",
      "torch.Size([4, 32, 45, 128])\n",
      "torch.Size([4, 32, 45, 128])\n",
      "torch.Size([4, 32, 45, 128])\n",
      "kv_seq_len 45 tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "indices should be either on cpu or on the same device as the indexed tensor (cpu)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[115], line 21\u001b[0m\n\u001b[1;32m     13\u001b[0m past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# attentiona mask\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# position_ids\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# specifies the position id of the corresponding hidden state tensor element\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# e.g. hid = [3, 4, 6] => pos_id = [0, 1, 2]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# past_key_value\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# if use cache, past key value will contain past kv values\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m               \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask_D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m               \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids_D\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m               \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m               \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m               \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[114], line 78\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(value_states\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkv_seq_len\u001b[39m\u001b[38;5;124m\"\u001b[39m, kv_seq_len, position_ids)\n\u001b[0;32m---> 78\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mrotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_seq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#####################################################\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[110], line 36\u001b[0m, in \u001b[0;36mLlamaRotaryEmbedding.forward\u001b[0;34m(self, q, k, v, position_ids, seq_len)\u001b[0m\n\u001b[1;32m     34\u001b[0m cos \u001b[38;5;241m=\u001b[39m cos\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [seq_len, dim]\u001b[39;00m\n\u001b[1;32m     35\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [seq_len, dim]\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m cos \u001b[38;5;241m=\u001b[39m \u001b[43mcos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [bs, 1, seq_len, dim]\u001b[39;00m\n\u001b[1;32m     37\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin[position_ids]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [bs, 1, seq_len, dim]\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# The first two dimensions of cos and sin are always 1, so we can `squeeze` them.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
     ]
    }
   ],
   "source": [
    "model = LlamaAttention(config)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# model.load(\"/home/fuchiang137/.cache/huggingface/hub/models--decapoda-research--llama-7b-hf/snapshots/5f98eefcc80e437ef68d457ad7bf167c2c6a1348/pytorch_model-00019-of-00033.bin\")\n",
    "model = model.to(device)\n",
    "\n",
    "data_D = data.to(device)\n",
    "attention_mask_D = attention_mask.to(device)\n",
    "position_ids_D = position_ids.to(device)\n",
    "# output = model(data)\n",
    "\n",
    "past_key_value = None\n",
    "\n",
    "# attentiona mask\n",
    "# position_ids\n",
    "# specifies the position id of the corresponding hidden state tensor element\n",
    "# e.g. hid = [3, 4, 6] => pos_id = [0, 1, 2]\n",
    "# past_key_value\n",
    "# if use cache, past key value will contain past kv values\n",
    "output = model(hidden_states=data_D,\n",
    "               attention_mask=attention_mask_D,\n",
    "               position_ids=position_ids_D,\n",
    "               past_key_value=past_key_value,\n",
    "               output_attentions=False,\n",
    "               use_cache=True,)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf78c6",
   "metadata": {},
   "source": [
    "## tensorRT MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b57022c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq length is not specified, since it is a dynamic size\n",
    "def trt_create(batch_size, hidden_size, intermediate_size, model):\n",
    "    \n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    builder = trt.Builder(logger)\n",
    "\n",
    "    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    # input\n",
    "    inputT0 = network.add_input('inputT0', trt.DataType.FLOAT, (batch_size, 1, -1, hidden_size))\n",
    "    \n",
    "#     network.mark_output(layer.get_output(0))\n",
    "\n",
    "    # dynamic shape optimization\n",
    "    profile = builder.create_optimization_profile();\n",
    "    profile.set_shape(\"inputT0\", (batch_size, 1, 1, hidden_size), (batch_size, 1, 2, hidden_size), (batch_size, 1, 3, hidden_size))\n",
    "    config.add_optimization_profile(profile)\n",
    "\n",
    "    slice_layer = network.add_slice(inputT0, start=(0, 0, 0, 0), shape=(2, 2, 2, 2), stride=(1, 1, 1, 1))\n",
    "\n",
    "#     # self.up_proj(x)\n",
    "#     up_proj_weight = model.up_proj.weight.clone().detach().cpu().numpy()\n",
    "#     up_proj_layer = network.add_fully_connected(inputT0, model.intermediate_size, up_proj_weight)\n",
    "\n",
    "#     # act_fn(self.gate_proj(x))\n",
    "#     gate_proj_weight = model.gate_proj.weight.clone().detach().cpu().numpy()\n",
    "#     gate_proj_layer = network.add_fully_connected(inputT0, model.intermediate_size, gate_proj_weight)\n",
    "\n",
    "#     selu_sigmoid_layer = network.add_activation(gate_proj_layer.get_output(0), type=trt.ActivationType.SIGMOID)\n",
    "#     selu_mult_layer = network.add_elementwise(gate_proj_layer.get_output(0), selu_sigmoid_layer.get_output(0), op=trt.ElementWiseOperation.PROD)\n",
    "\n",
    "#     # act_fn(self.gate_proj(x)) * self.up_proj(x)\n",
    "#     before_down_proj_layer = network.add_elementwise(selu_mult_layer.get_output(0), up_proj_layer.get_output(0), op=trt.ElementWiseOperation.PROD)\n",
    "\n",
    "#     down_proj_weight = model.down_proj.weight.clone().detach().cpu().numpy()\n",
    "#     down_proj_layer = network.add_fully_connected(before_down_proj_layer.get_output(0), hidden_size, down_proj_weight)\n",
    "\n",
    "    # output\n",
    "    network.mark_output(slice_layer.get_output(0))\n",
    "\n",
    "    engineString = builder.build_serialized_network(network, config)\n",
    "    \n",
    "    return engineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2e7f204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/28/2023-07:31:43] [TRT] [E] 4: (Unnamed Layer* 0) [Slice]: out of bounds slice, input dimensions = [4,1,-1,4096], start = [0,0,0,0], size = [2,2,2,2], stride = [1,1,1,1].\n",
      "[09/28/2023-07:31:43] [TRT] [E] 4: [network.cpp::validate::3121] Error Code 4: Internal Error (Layer (Unnamed Layer* 0) [Slice] failed validation)\n"
     ]
    }
   ],
   "source": [
    "trt_engineStr = trt_create(batch_size, hidden_size, intermediate_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4a16799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_inference(batch_size, hidden_size, engineString, raw_data, up_proj):\n",
    "#     print(engineString)\n",
    "#     print(\"Runtime\")\n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # dynamic shape configure\n",
    "#     print(\"Set input shape\", (batch_size, 1, hidden_size))\n",
    "#     context.set_input_shape(\"inputT0\", (batch_size, 1, hidden_size))\n",
    "#     context.set_binding_shape(0, (batch_size, 1, hidden_size))\n",
    "#     origin_inputshape = context.get_binding_shape(0)\n",
    "\n",
    "#     print(\"Set input shape completed\")\n",
    "\n",
    "    data = np.array(raw_data)\n",
    "\n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "#     print(\"Reshaping\")\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
    "#     print(\"Reshaped\")\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "\n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "\n",
    "    # execute\n",
    "#     print(\"execute\")\n",
    "    context.execute_async_v2([int(inputD0), int(outputD0)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "\n",
    "    # wait for everythidden_sizeg\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(outputD0)\n",
    "\n",
    "    return outputH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17cf97c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_trt : (4, 1, 4096)\n",
      "[[[ 2.0781114  4.51184    3.0770564 ... -2.6064956 -2.116741  -2.7058382]]\n",
      "\n",
      " [[ 2.0781114  4.51184    3.0770564 ... -2.6064956 -2.116741  -2.7058382]]\n",
      "\n",
      " [[ 2.0781114  4.51184    3.0770564 ... -2.6064956 -2.116741  -2.7058382]]\n",
      "\n",
      " [[ 2.0781114  4.51184    3.0770564 ... -2.6064956 -2.116741  -2.7058382]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26430/1054781966.py:22: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
      "/tmp/ipykernel_26430/1054781966.py:22: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n"
     ]
    }
   ],
   "source": [
    "up_proj_weight = model.up_proj.weight.clone().detach().cpu().numpy()\n",
    "\n",
    "trt_output = trt_inference(batch_size, hidden_size, trt_engineStr, data, up_proj_weight)\n",
    "\n",
    "trt_output = trt_output.reshape(batch_size, seq_len, hidden_size)\n",
    "print(\"output_trt :\", trt_output.shape)\n",
    "print(trt_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09905f5b",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008017b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97297d8",
   "metadata": {},
   "source": [
    "### Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf757533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch memory exe 0.2631836 ms\n"
     ]
    }
   ],
   "source": [
    "torch_start = time.time_ns()\n",
    "\n",
    "output = model(data_D)\n",
    "\n",
    "torch_complete = time.time_ns()\n",
    "\n",
    "print(\"torch memory exe\", (torch_complete - torch_start) / 10e6, \"ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f655cc3",
   "metadata": {},
   "source": [
    "### TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fafa7d",
   "metadata": {},
   "source": [
    "### profile CPU/GPU time for tensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd9d1736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_trt_inference(batch_size, hidden_size, engineString, raw_data, up_proj):\n",
    "    trt_prep_start = time.time_ns()\n",
    "    \n",
    "    logger = trt.Logger(trt.Logger.ERROR)\n",
    "    engine = trt.Runtime(logger).deserialize_cuda_engine(engineString)\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    trt_prep_complete = time.time_ns()\n",
    "\n",
    "    data = np.array(raw_data)\n",
    "\n",
    "    inputH0 = np.ascontiguousarray(data.reshape(-1))\n",
    "    outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
    "\n",
    "    memory_alloc_complete = time.time_ns()\n",
    "\n",
    "    _, stream = cudart.cudaStreamCreate()\n",
    "\n",
    "    # initialize input and output data\n",
    "    _, inputD0 = cudart.cudaMallocAsync(inputH0.nbytes, stream)\n",
    "    _, outputD0 = cudart.cudaMallocAsync(outputH0.nbytes, stream)\n",
    "\n",
    "    # move input to device\n",
    "    cudart.cudaMemcpyAsync(inputD0, inputH0.ctypes.data, inputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyHostToDevice, stream)\n",
    "\n",
    "    # execute\n",
    "    context.execute_async_v2([int(inputD0), int(outputD0)], stream)\n",
    "\n",
    "    # move output back to host\n",
    "    cudart.cudaMemcpyAsync(outputH0.ctypes.data, outputD0, outputH0.nbytes, cudart.cudaMemcpyKind.cudaMemcpyDeviceToHost, stream)\n",
    "\n",
    "    # wait for everythidden_sizeg\n",
    "    cudart.cudaStreamSynchronize(stream)\n",
    "\n",
    "    cudart.cudaStreamDestroy(stream)\n",
    "    cudart.cudaFree(inputD0)\n",
    "    cudart.cudaFree(outputD0)\n",
    "\n",
    "    trt_complete = time.time_ns()\n",
    "    \n",
    "    print(\"trt_prep\", (trt_prep_complete - trt_prep_start) / 10e6, \"ms\")\n",
    "    print(\"memory_alloc CPU\", (memory_alloc_complete - trt_prep_complete) / 10e6, \"ms\")\n",
    "    print(\"trt memory alloc & mv & exe\", (trt_complete - memory_alloc_complete) / 10e6, \"ms\")\n",
    "\n",
    "    return outputH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8c0f86b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trt_prep 15.1114614 ms\n",
      "memory_alloc CPU 0.0241049 ms\n",
      "trt memory alloc & mv & exe 0.1599591 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26430/2630322136.py:13: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n",
      "/tmp/ipykernel_26430/2630322136.py:13: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  outputH0 = np.empty(context.get_binding_shape(1), dtype=trt.nptype(engine.get_binding_dtype(1)))\n"
     ]
    }
   ],
   "source": [
    "trt_output = profile_trt_inference(batch_size, hidden_size, trt_engineStr, data, up_proj_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe740c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
